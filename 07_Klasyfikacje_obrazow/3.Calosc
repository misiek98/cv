{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled100.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNSRcSokCsjBHGDw6F1z6zu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/misiek98/cv/blob/master/07_Klasyfikacje_obrazow/3.Calosc\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xkvyf2dYkWHt"
      },
      "source": [
        "from tensorflow.keras import callbacks\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "import plotly.graph_objects as go\n",
        "import plotly.offline as po\n",
        "from plotly.subplots import make_subplots\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import argparse\n",
        "import pickle  # do zachowania mapowania kodów i etykiet w procesie trenowania\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8L34hBAykc2R"
      },
      "source": [
        "import pydrive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "downloaded = drive.CreateFile({'id':\"1j1eTYzYPcooRkPlv1V3KHs_XBfKP_q2G\"})\n",
        "downloaded.GetContentFile('folder.zip')\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AKcP18okc0M"
      },
      "source": [
        "!unzip -q /content/folder.zip"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XcwIhO5kcxy"
      },
      "source": [
        "MODEL_NAME = 'LeNet5'\n",
        "LEARNING_RATE = 0.001\n",
        "EPOCHS = 30\n",
        "BATCH_SIZE = 32\n",
        "INPUT_SHAPE = (150, 150, 3)\n",
        "TRAIN_DIR = r'/content/images/train'\n",
        "VALID_DIR = r'/content/images/valid'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQf5_feWkcvl",
        "outputId": "4efb0c22-306e-4837-a227-994c805e6c63"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rotation_range=30,\n",
        "                                   rescale=1. / 255.,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True,\n",
        "                                   fill_mode='nearest')\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1. / 255.)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(directory=TRAIN_DIR,\n",
        "                                                    target_size=INPUT_SHAPE[:2],\n",
        "                                                    batch_size=BATCH_SIZE,\n",
        "                                                    class_mode='binary')\n",
        "\n",
        "valid_generator = valid_datagen.flow_from_directory(directory=VALID_DIR,\n",
        "                                                    target_size=INPUT_SHAPE[:2],\n",
        "                                                    batch_size=BATCH_SIZE,\n",
        "                                                    class_mode='binary')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 778 images belonging to 2 classes.\n",
            "Found 222 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTzavk_5l1Q0"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters=6, kernel_size=(3, 3), input_shape=INPUT_SHAPE, activation='relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=120, activation='relu'))\n",
        "model.add(Dense(units=84, activation='relu'))\n",
        "model.add(Dense(units=1, activation='sigmoid'))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDktaiTdku8h"
      },
      "source": [
        "model.compile(optimizer=Adam(learning_rate=LEARNING_RATE),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XDdH-_Vk4y9",
        "outputId": "f3e91273-4d0b-4858-82e1-96ff26e3334c"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 148, 148, 6)       168       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 74, 74, 6)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 72, 72, 16)        880       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 16)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 20736)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 120)               2488440   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 84)                10164     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 85        \n",
            "=================================================================\n",
            "Total params: 2,499,737\n",
            "Trainable params: 2,499,737\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O32DDwL3ku6y",
        "outputId": "0d78dc01-2bd0-43a2-c9bd-3980556074df"
      },
      "source": [
        "history = model.fit_generator(generator=train_generator,\n",
        "                              steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
        "                              validation_data=valid_generator,\n",
        "                              validation_steps=valid_generator.samples // BATCH_SIZE,\n",
        "                              epochs=EPOCHS)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning:\n",
            "\n",
            "`Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "24/24 [==============================] - 73s 2s/step - loss: 0.7230 - accuracy: 0.5670 - val_loss: 0.6370 - val_accuracy: 0.7031\n",
            "Epoch 2/30\n",
            "24/24 [==============================] - 44s 2s/step - loss: 0.6434 - accuracy: 0.6515 - val_loss: 0.5861 - val_accuracy: 0.7083\n",
            "Epoch 3/30\n",
            "24/24 [==============================] - 44s 2s/step - loss: 0.5991 - accuracy: 0.6863 - val_loss: 0.5565 - val_accuracy: 0.7500\n",
            "Epoch 4/30\n",
            "24/24 [==============================] - 44s 2s/step - loss: 0.5508 - accuracy: 0.7279 - val_loss: 0.6104 - val_accuracy: 0.7083\n",
            "Epoch 5/30\n",
            "24/24 [==============================] - 44s 2s/step - loss: 0.5404 - accuracy: 0.7480 - val_loss: 0.6647 - val_accuracy: 0.6406\n",
            "Epoch 6/30\n",
            "24/24 [==============================] - 44s 2s/step - loss: 0.5275 - accuracy: 0.7534 - val_loss: 0.5956 - val_accuracy: 0.6875\n",
            "Epoch 7/30\n",
            "24/24 [==============================] - 43s 2s/step - loss: 0.4982 - accuracy: 0.7708 - val_loss: 0.5588 - val_accuracy: 0.7448\n",
            "Epoch 8/30\n",
            "24/24 [==============================] - 43s 2s/step - loss: 0.5266 - accuracy: 0.7520 - val_loss: 0.5713 - val_accuracy: 0.6719\n",
            "Epoch 9/30\n",
            "24/24 [==============================] - 44s 2s/step - loss: 0.4805 - accuracy: 0.7708 - val_loss: 0.5789 - val_accuracy: 0.6667\n",
            "Epoch 10/30\n",
            "24/24 [==============================] - 43s 2s/step - loss: 0.4905 - accuracy: 0.7775 - val_loss: 0.5856 - val_accuracy: 0.7448\n",
            "Epoch 11/30\n",
            "24/24 [==============================] - 44s 2s/step - loss: 0.4648 - accuracy: 0.7747 - val_loss: 0.5352 - val_accuracy: 0.7604\n",
            "Epoch 12/30\n",
            "24/24 [==============================] - 44s 2s/step - loss: 0.4845 - accuracy: 0.7681 - val_loss: 0.5502 - val_accuracy: 0.7031\n",
            "Epoch 13/30\n",
            "24/24 [==============================] - 44s 2s/step - loss: 0.4800 - accuracy: 0.7748 - val_loss: 0.5521 - val_accuracy: 0.7344\n",
            "Epoch 14/30\n",
            "24/24 [==============================] - 45s 2s/step - loss: 0.4543 - accuracy: 0.7802 - val_loss: 0.6219 - val_accuracy: 0.6875\n",
            "Epoch 15/30\n",
            "24/24 [==============================] - 43s 2s/step - loss: 0.4618 - accuracy: 0.7882 - val_loss: 0.6124 - val_accuracy: 0.6823\n",
            "Epoch 16/30\n",
            "24/24 [==============================] - 44s 2s/step - loss: 0.4602 - accuracy: 0.7949 - val_loss: 0.5904 - val_accuracy: 0.7083\n",
            "Epoch 17/30\n",
            "24/24 [==============================] - 45s 2s/step - loss: 0.4480 - accuracy: 0.7976 - val_loss: 0.5477 - val_accuracy: 0.6979\n",
            "Epoch 18/30\n",
            "24/24 [==============================] - 44s 2s/step - loss: 0.4476 - accuracy: 0.7882 - val_loss: 0.6016 - val_accuracy: 0.6406\n",
            "Epoch 19/30\n",
            "24/24 [==============================] - 44s 2s/step - loss: 0.4544 - accuracy: 0.7802 - val_loss: 0.5607 - val_accuracy: 0.7292\n",
            "Epoch 20/30\n",
            "24/24 [==============================] - 44s 2s/step - loss: 0.4569 - accuracy: 0.7842 - val_loss: 0.5625 - val_accuracy: 0.6875\n",
            "Epoch 21/30\n",
            "24/24 [==============================] - 44s 2s/step - loss: 0.4633 - accuracy: 0.7882 - val_loss: 0.5587 - val_accuracy: 0.7656\n",
            "Epoch 22/30\n",
            "24/24 [==============================] - 45s 2s/step - loss: 0.4521 - accuracy: 0.8043 - val_loss: 0.5667 - val_accuracy: 0.7083\n",
            "Epoch 23/30\n",
            "24/24 [==============================] - 44s 2s/step - loss: 0.4672 - accuracy: 0.7962 - val_loss: 0.5644 - val_accuracy: 0.7135\n",
            "Epoch 24/30\n",
            "24/24 [==============================] - 44s 2s/step - loss: 0.4473 - accuracy: 0.7909 - val_loss: 0.5444 - val_accuracy: 0.7292\n",
            "Epoch 25/30\n",
            "24/24 [==============================] - 44s 2s/step - loss: 0.4175 - accuracy: 0.8164 - val_loss: 0.5654 - val_accuracy: 0.7344\n",
            "Epoch 26/30\n",
            "24/24 [==============================] - 46s 2s/step - loss: 0.4443 - accuracy: 0.7922 - val_loss: 0.6309 - val_accuracy: 0.6719\n",
            "Epoch 27/30\n",
            "24/24 [==============================] - 44s 2s/step - loss: 0.4675 - accuracy: 0.7668 - val_loss: 0.5681 - val_accuracy: 0.7240\n",
            "Epoch 28/30\n",
            "24/24 [==============================] - 46s 2s/step - loss: 0.4250 - accuracy: 0.8016 - val_loss: 0.5333 - val_accuracy: 0.7396\n",
            "Epoch 29/30\n",
            "24/24 [==============================] - 44s 2s/step - loss: 0.4196 - accuracy: 0.8083 - val_loss: 0.5382 - val_accuracy: 0.7552\n",
            "Epoch 30/30\n",
            "24/24 [==============================] - 44s 2s/step - loss: 0.4248 - accuracy: 0.8016 - val_loss: 0.5303 - val_accuracy: 0.7292\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0FLluUAku4q"
      },
      "source": [
        "def plot_hist(history, filename):\n",
        "    hist = pd.DataFrame(history.history)\n",
        "    hist['epoch'] = history.epoch\n",
        "\n",
        "    fig = make_subplots(rows=2, cols=1, subplot_titles=('Accuracy', 'Loss'))\n",
        "\n",
        "    fig.add_trace(go.Scatter(x=hist['epoch'], y=hist['accuracy'], name='train_accuracy',\n",
        "                  mode='markers+lines', marker_color='#f29407'), row=1, col=1)\n",
        "\n",
        "    fig.add_trace(go.Scatter(x=hist['epoch'], y=hist['val_accuracy'],\n",
        "                  name='val_accuracy', mode='markers+lines', marker_color='#0771f2'), row=1, col=1)\n",
        "\n",
        "    fig.add_trace(go.Scatter(x=hist['epoch'], y=hist['loss'], name='train_loss',\n",
        "                  mode='markers+lines', marker_color='#f29407'), row=2, col=1)\n",
        "\n",
        "    fig.add_trace(go.Scatter(x=hist['epoch'], y=hist['val_loss'], name='val_loss',\n",
        "                  mode='markers+lines', marker_color='#0771f2'), row=2, col=1)\n",
        "\n",
        "    fig.update_xaxes(title_text='Liczba epok', row=1, col=1)\n",
        "    fig.update_xaxes(title_text='Liczba epok', row=2, col=1)\n",
        "\n",
        "    fig.update_xaxes(title_text='Accuracy', row=1, col=1)\n",
        "    fig.update_xaxes(title_text='Loss', row=2, col=1)\n",
        "\n",
        "    fig.update_layout(width=1400, height=1000, title=f'Metrics: {MODEL_NAME}')\n",
        "\n",
        "    po.plot(fig, filename=filename, auto_open=False)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLVCg4jttzHU"
      },
      "source": [
        "plot_hist(history, 'Gówno.html')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wV2s4wS-kuxw",
        "outputId": "5747aa72-229a-492d-8b21-f0cb1e9d6de3"
      },
      "source": [
        "test = '/content/images/test'\n",
        "\n",
        "datagen = ImageDataGenerator(rescale=1. / 255.)\n",
        "\n",
        "test_generator = datagen.flow_from_directory(directory=test,\n",
        "                                             target_size=INPUT_SHAPE[:2],\n",
        "                                             batch_size=BATCH_SIZE,\n",
        "                                             class_mode='binary')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 113 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "na3REOneuFPm"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZFzdwWiuJNc",
        "outputId": "497313d9-3ac8-4f78-d55f-5885de7060fc"
      },
      "source": [
        "y_prob = model.predict_generator(test_generator, workers=1)\n",
        "y_prob = y_prob.ravel()\n",
        "\n",
        "y_true = test_generator.classes\n",
        "\n",
        "predictions = pd.DataFrame({'y_prob': y_prob, 'y_true': y_true}, index=test_generator.filenames)\n",
        "predictions['y_pred'] = predictions['y_prob'].apply(lambda x: 1 if x > 0.5 else 0)\n",
        "predictions['is_incorrect'] = (predictions['y_true'] != predictions['y_pred']) * 1\n",
        "errors = list(predictions[predictions['is_incorrect'] == 1].index)\n",
        "print(predictions.head())\n",
        "\n",
        "y_pred = predictions['y_pred'].values\n",
        "\n",
        "print(f'[INFO] Macierz konfuzji:\\n{confusion_matrix(y_true, y_pred)}')\n",
        "print(f'[INFO] Raport klasyfikacji:\\n{classification_report(y_true, y_pred, target_names=test_generator.class_indices.keys())}')\n",
        "print(f'[INFO] Dokładność modelu: {accuracy_score(y_true, y_pred) * 100:.2f}%')\n",
        "\n",
        "label_map = test_generator.class_indices\n",
        "label_map = dict((v, k) for k, v in label_map.items())\n",
        "predictions['class'] = predictions['y_pred'].apply(lambda x: label_map[x])\n",
        "\n",
        "predictions.to_csv(r'output\\predictions.csv')\n",
        "\n",
        "print(f'[INFO] Błędnie sklasyfikowano: {len(errors)}\\n[INFO] Nazwy plików:')\n",
        "for error in errors:\n",
        "    print(error)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning:\n",
            "\n",
            "`Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                      y_prob  y_true  y_pred  is_incorrect\n",
            "horse/00000621.jpg  0.887910       0       1             1\n",
            "horse/00000622.jpg  0.101299       0       0             0\n",
            "horse/00000623.jpg  0.411757       0       0             0\n",
            "horse/00000624.jpg  0.033460       0       0             0\n",
            "horse/00000626.jpg  0.382054       0       0             0\n",
            "[INFO] Macierz konfuzji:\n",
            "[[34 26]\n",
            " [22 31]]\n",
            "[INFO] Raport klasyfikacji:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       horse       0.61      0.57      0.59        60\n",
            "        lion       0.54      0.58      0.56        53\n",
            "\n",
            "    accuracy                           0.58       113\n",
            "   macro avg       0.58      0.58      0.57       113\n",
            "weighted avg       0.58      0.58      0.58       113\n",
            "\n",
            "[INFO] Dokładność modelu: 57.52%\n",
            "[INFO] Błędnie sklasyfikowano: 48\n",
            "[INFO] Nazwy plików:\n",
            "horse/00000621.jpg\n",
            "horse/00000634.jpg\n",
            "horse/00000640.jpg\n",
            "horse/00000641.jpg\n",
            "horse/00000646.jpg\n",
            "horse/00000648.jpg\n",
            "horse/00000649.jpg\n",
            "horse/00000652.jpg\n",
            "horse/00000653.jpg\n",
            "horse/00000655.jpg\n",
            "horse/00000656.jpg\n",
            "horse/00000657.JPG\n",
            "horse/00000658.jpg\n",
            "horse/00000659.jpg\n",
            "horse/00000663.jpg\n",
            "horse/00000665.jpg\n",
            "horse/00000675.jpg\n",
            "horse/00000678.jpg\n",
            "horse/00000683.jpg\n",
            "horse/00000687.jpg\n",
            "horse/00000688.jpg\n",
            "horse/00000690.jpg\n",
            "horse/00000692.jpg\n",
            "horse/00000693.jpg\n",
            "horse/00000698.jpg\n",
            "horse/00000703.JPG\n",
            "lion/00000645.jpg\n",
            "lion/00000647.jpg\n",
            "lion/00000649.jpg\n",
            "lion/00000654.jpg\n",
            "lion/00000671.jpg\n",
            "lion/00000686.jpg\n",
            "lion/00000688.jpg\n",
            "lion/00000695.JPG\n",
            "lion/00000699.jpg\n",
            "lion/00000707.jpg\n",
            "lion/00000708.jpg\n",
            "lion/00000733.jpg\n",
            "lion/00000735.jpg\n",
            "lion/00000737.jpg\n",
            "lion/00000738.jpg\n",
            "lion/00000739.jpg\n",
            "lion/00000743.jpg\n",
            "lion/00000774.jpg\n",
            "lion/00000783.jpg\n",
            "lion/00000788.JPG\n",
            "lion/00000796.jpg\n",
            "lion/00000813.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evqyWJAxm_z6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}